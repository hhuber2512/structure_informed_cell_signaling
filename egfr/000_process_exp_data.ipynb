{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Serialization\n",
    "include(\"define_test_train.jl\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Experimental Data from CSV\n",
    "This script extracts relevant inputs from the experimental data reported in Kholodenko et al. For example, it extracts what timepoints to save at for the timecourse simulation, then serializes the files. As another example, it extracts the ligand dose inputs (in nM).\n",
    "\n",
    "Outputs 8 dictionaries, one per experimental measurement, with the following entries:\n",
    "\n",
    "000_processed_grb_egfr_20.dict: <br>\n",
    "\n",
    "Dict{String, Any} with 4 entries: <br>\n",
    "  \"save_at\"                => [0, 15, 30, 45, 60, 120] <br>\n",
    "  \"reponse\"                => [0.0, 18.06, 15.79, 8.66, 6.44, 4.7] <br>\n",
    "  \"ligand_simulation (nM)\" => 20.0 <br>\n",
    "  \"average_error\"          => 5 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = readdir(\"data\")\n",
    "sort_files = data_files .!= \".DS_Store\"\n",
    "data_files = sort(data_files[sort_files]) #sort to ensure consistent order\n",
    "sort_files = data_files .!= \"kholodenko1.xml\"\n",
    "data_files = sort(data_files[sort_files])\n",
    "sort_files = data_files .!= \"predicted_kd.csv\"\n",
    "data_files = sort(data_files[sort_files])\n",
    "data = [DataFrame(CSV.File(\"data/$(data_files[i])\")) for i in 1:length(data_files)]\n",
    "ligand_stimulation = [20,20,0.2,2,20,2,20,20] #consistent with sorted order of files\n",
    "my_keys = [\"save_at\", \"response\",\"ligand_simulation (nM)\", \"average_error\"]\n",
    "average_error = [2.5, 5.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0] ##took average error per species, rounded to nearest 0.5\n",
    "my_values = [[data[i][!,\"x\"], data[i][!,\" y\"],ligand_stimulation[i], average_error[i]] for i in 1:length(data_files)]\n",
    "processed_dictionary = [Dict(my_keys .=> my_values[i]) for i in 1:length(data_files)]\n",
    "output_names = [replace(data_files[i], \".csv\" => \"\") for i in 1:length(data_files)]\n",
    "output_names = [\"000_processed_\" * output_names[i] * \".dict\" for i in 1:length(data_files)]\n",
    "[serialize(\"outputs/$(output_names[i])\", processed_dictionary[i]) for i in 1:length(data_files)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{String}:\n",
       " \"grb_egfr_20.csv\"\n",
       " \"grb_shc_20.csv\"\n",
       " \"p_egfr_02.csv\"\n",
       " \"p_egfr_2.csv\"\n",
       " \"p_egfr_20.csv\"\n",
       " \"p_plcg_2.csv\"\n",
       " \"p_plcg_20.csv\"\n",
       " \"p_shc_20.csv\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Training Data and Standard Deviations as Dictionaries of 1D Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pSHC as test data\n",
    "data_files = return_training_data_names_w_pshc_test()\n",
    "data_points = Array{Float64}(undef,0)\n",
    "std_dev = Array{Float64}(undef,0)\n",
    "[append!(data_points, deserialize(\"outputs/$(i)\")[\"response\"]) for i in data_files]\n",
    "[append!(std_dev, fill(deserialize(\"outputs/$(i)\")[\"average_error\"],length(deserialize(\"outputs/$(i)\")[\"response\"]))) for i in data_files]\n",
    "serialize(\"outputs/000_training_data_w_pshc_test.dict\", Dict(\"response\"=>data_points, \"average_error\"=>std_dev))\n",
    "\n",
    "#pEGFR as test data\n",
    "data_files = return_training_data_names_w_egfr_test()\n",
    "data_points = Array{Float64}(undef,0)\n",
    "std_dev = Array{Float64}(undef,0)\n",
    "[append!(data_points, deserialize(\"outputs/$(i)\")[\"response\"]) for i in data_files]\n",
    "[append!(std_dev, fill(deserialize(\"outputs/$(i)\")[\"average_error\"],length(deserialize(\"outputs/$(i)\")[\"response\"]))) for i in data_files]\n",
    "serialize(\"outputs/000_training_data_w_pegfr_test.dict\", Dict(\"response\"=>data_points, \"average_error\"=>std_dev))\n",
    "\n",
    "#pSHC and SHC:GRB2 as test data\n",
    "data_files = return_training_data_names_w_pshc_grb2shc_test()\n",
    "data_points = Array{Float64}(undef,0)\n",
    "std_dev = Array{Float64}(undef,0)\n",
    "[append!(data_points, deserialize(\"outputs/$(i)\")[\"response\"]) for i in data_files]\n",
    "[append!(std_dev, fill(deserialize(\"outputs/$(i)\")[\"average_error\"],length(deserialize(\"outputs/$(i)\")[\"response\"]))) for i in data_files]\n",
    "serialize(\"outputs/000_training_data_w_pshc_grb2shc_test.dict\", Dict(\"response\"=>data_points, \"average_error\"=>std_dev))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and Store Kd Predictions & AlphaFold ranking score as Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(CSV.File(\"data/predicted_kd.csv\"))\n",
    "parameters = String.(data[!,\"parameter\"])\n",
    "convert_to_nM = 10^9\n",
    "mean_predicted = log10.(data[!,\"predicted_Kd(M)\"].*convert_to_nM)\n",
    "mean_reported = log10.(data[!,\"reported_Kd(M)\"].*convert_to_nM)\n",
    "lambda = data[!,\"AF_ranking_score\"]\n",
    "mask0 = findall(lambda .< 0.5)\n",
    "lambda[mask0] .= 0\n",
    "mask1 = findall(lambda .>= 0.5)\n",
    "lambda[mask1] .= 1\n",
    "dictionary_definition = Dict(parameters[i]=>Dict(\"mean\"=>mean_predicted[i],\"std_dev\"=>1.3,\"lambda\"=>lambda[i]) for i in 1:length(parameters))\n",
    "dictionary_definition_reported = Dict(parameters[i]=>Dict(\"mean\"=>mean_reported[i],\"std_dev\"=>1.3,\"lambda\"=>lambda[i]) for i in 1:length(parameters))\n",
    "serialize(\"outputs/000_augmentation_parameters_predicted_kd_rank_score.dict\", dictionary_definition)\n",
    "serialize(\"outputs/000_augmentation_parameters_reported_kd_rank_score.dict\", dictionary_definition_reported);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and Store Kd Predictions & AlphaFold ipTM as Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(CSV.File(\"data/predicted_kd.csv\"))\n",
    "parameters = String.(data[!,\"parameter\"])\n",
    "convert_to_nM = 10^9\n",
    "mean_predicted = log10.(data[!,\"predicted_Kd(M)\"].*convert_to_nM)\n",
    "mean_reported = log10.(data[!,\"reported_Kd(M)\"].*convert_to_nM)\n",
    "lambda = data[!,\"AF_ipTM\"]\n",
    "dictionary_definition = Dict(parameters[i]=>Dict(\"mean\"=>mean_predicted[i],\"std_dev\"=>1.3,\"lambda\"=>lambda[i]) for i in 1:length(parameters))\n",
    "dictionary_definition_reported = Dict(parameters[i]=>Dict(\"mean\"=>mean_reported[i],\"std_dev\"=>1.3,\"lambda\"=>lambda[i]) for i in 1:length(parameters))\n",
    "serialize(\"outputs/000_augmentation_parameters_predicted_kd_iptm.dict\", dictionary_definition)\n",
    "serialize(\"outputs/000_augmentation_parameters_reported_kd_iptm.dict\", dictionary_definition_reported);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and Store Kd Predictions with No AlphaFold Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(CSV.File(\"data/predicted_kd.csv\"))\n",
    "parameters = String.(data[!,\"parameter\"])\n",
    "convert_to_nM = 10^9\n",
    "mean_predicted = log10.(data[!,\"predicted_Kd(M)\"].*convert_to_nM)\n",
    "mean_reported = log10.(data[!,\"reported_Kd(M)\"].*convert_to_nM)\n",
    "lambda = fill(1, length(parameters))\n",
    "dictionary_definition = Dict(parameters[i]=>Dict(\"mean\"=>mean_predicted[i],\"std_dev\"=>1.3,\"lambda\"=>lambda[i]) for i in 1:length(parameters))\n",
    "serialize(\"outputs/000_augmentation_parameters_predicted_kd_no_AF3_confidence.dict\", dictionary_definition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia(emcee-4-thread-1.11) 1.11.4",
   "language": "julia",
   "name": "julia_emcee-4-thread-1.11_-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
